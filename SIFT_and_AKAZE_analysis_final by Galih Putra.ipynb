{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPlLVKjziqBO",
        "outputId": "8560dba5-65f8-4e4f-fc1b-6a47515b9d74"
      },
      "id": "lPlLVKjziqBO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPytrKvhgFY0",
        "outputId": "6473b974-d853-4a8a-ce3f-76b55507a1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless openpyxl pandas scikit-learn"
      ],
      "id": "BPytrKvhgFY0"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnHrvUKpvByb",
        "outputId": "0729c248-babd-4ec0-e907-165abdc8d66c"
      },
      "id": "pnHrvUKpvByb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b143e7-249d-4a32-ba99-9fb5f6b686b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47b143e7-249d-4a32-ba99-9fb5f6b686b6",
        "outputId": "774b68c5-49f2-436d-bbcc-2b9e1b9588b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found: /content/drive/MyDrive/Colab Notebooks/PCD/Output File\\comparison_regression_sift_akaze.xlsx. Creating a new file.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from openpyxl import load_workbook\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Function to load images from a folder\n",
        "def load_images_from_folder(base_path):\n",
        "    images = {}\n",
        "    for root, _, files in os.walk(base_path):\n",
        "        folder_name = os.path.basename(root)\n",
        "        images[folder_name] = [os.path.join(root, f) for f in files if f.endswith(\".ppm\")]\n",
        "    return images\n",
        "\n",
        "# Function to calculate regression metrics between two image descriptors\n",
        "def calculate_regression_metrics(image1_path, image2_path, method=\"SIFT\"):\n",
        "    image1 = cv2.imread(image1_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image2 = cv2.imread(image2_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image1 is None or image2 is None:\n",
        "        return 0, 0, 0, 0, 0\n",
        "\n",
        "    if method == \"SIFT\":\n",
        "        detector = cv2.SIFT_create()\n",
        "    elif method == \"AKAZE\":\n",
        "        detector = cv2.AKAZE_create()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported method. Use 'SIFT' or 'AKAZE'.\")\n",
        "\n",
        "    keypoints1, descriptors1 = detector.detectAndCompute(image1, None)\n",
        "    keypoints2, descriptors2 = detector.detectAndCompute(image2, None)\n",
        "\n",
        "    if descriptors1 is None or descriptors2 is None:\n",
        "        return 0, 0, 0, 0, 0\n",
        "\n",
        "    min_length = min(descriptors1.shape[0], descriptors2.shape[0])\n",
        "    descriptors1 = descriptors1[:min_length].flatten()\n",
        "    descriptors2 = descriptors2[:min_length].flatten()\n",
        "\n",
        "    mse = mean_squared_error(descriptors1, descriptors2)\n",
        "    mae = mean_absolute_error(descriptors1, descriptors2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(descriptors1, descriptors2)\n",
        "\n",
        "    return len(keypoints1), len(keypoints2), mse, mae, rmse, r2\n",
        "\n",
        "# Function to evaluate keypoint matching and save the matches as an image\n",
        "def evaluate_matching_and_save(image1_path, image2_path, output_dir, method=\"SIFT\"):\n",
        "    # Load images\n",
        "    image1 = cv2.imread(image1_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image2 = cv2.imread(image2_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image1 is None or image2 is None:\n",
        "        return 0, 0, 0, \"Image not loaded\", \"Image not loaded\", \"Image not loaded\"\n",
        "\n",
        "    # Initialize detector and matcher\n",
        "    if method == \"SIFT\":\n",
        "        detector = cv2.SIFT_create()\n",
        "        matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "    elif method == \"AKAZE\":\n",
        "        detector = cv2.AKAZE_create()\n",
        "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported method. Use 'SIFT' or 'AKAZE'.\")\n",
        "\n",
        "    # Detect and compute keypoints and descriptors\n",
        "    keypoints1, descriptors1 = detector.detectAndCompute(image1, None)\n",
        "    keypoints2, descriptors2 = detector.detectAndCompute(image2, None)\n",
        "\n",
        "    if descriptors1 is None or descriptors2 is None:\n",
        "        return 0, 0, 0, \"No descriptors found\", \"No descriptors found\", \"No descriptors found\"\n",
        "\n",
        "    # Match descriptors and sort by distance\n",
        "    matches = matcher.match(descriptors1, descriptors2)\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "    # Filter inliers and outliers based on distance threshold\n",
        "    threshold = 1.5 * np.median([m.distance for m in matches])\n",
        "    inliers = [m for m in matches if m.distance <= threshold]\n",
        "    outliers = [m for m in matches if m.distance > threshold]\n",
        "\n",
        "    # Draw inliers with lines\n",
        "    inlier_image = cv2.drawMatches(image1, keypoints1, image2, keypoints2, inliers, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "    # Draw outliers with lines\n",
        "    outlier_image = cv2.drawMatches(image1, keypoints1, image2, keypoints2, outliers, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "    # Combine inliers and outliers into one image (outliers as points only)\n",
        "    combined_image = inlier_image.copy()\n",
        "    for match in outliers:\n",
        "        pt1 = tuple(map(int, keypoints1[match.queryIdx].pt))\n",
        "        pt2 = (int(keypoints2[match.trainIdx].pt[0] + image1.shape[1]), int(keypoints2[match.trainIdx].pt[1]))\n",
        "        cv2.circle(combined_image, pt1, 3, (0, 0, 255), -1)\n",
        "        cv2.circle(combined_image, pt2, 3, (0, 0, 255), -1)\n",
        "\n",
        "    # Determine folder structure based on input image path\n",
        "    folder_name = os.path.basename(os.path.dirname(image1_path))\n",
        "    subfolder_path = os.path.join(output_dir, folder_name)\n",
        "    os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "    # Save images\n",
        "    inlier_image_path = os.path.join(subfolder_path, f\"inliers_{os.path.basename(image1_path)}_{os.path.basename(image2_path)}.png\")\n",
        "    outlier_image_path = os.path.join(subfolder_path, f\"outliers_{os.path.basename(image1_path)}_{os.path.basename(image2_path)}.png\")\n",
        "    combined_image_path = os.path.join(subfolder_path, f\"combined_{os.path.basename(image1_path)}_{os.path.basename(image2_path)}.png\")\n",
        "    cv2.imwrite(inlier_image_path, inlier_image)\n",
        "    cv2.imwrite(outlier_image_path, outlier_image)\n",
        "    cv2.imwrite(combined_image_path, combined_image)\n",
        "\n",
        "    return len(matches), len(inliers), len(outliers), inlier_image_path, outlier_image_path, combined_image_path\n",
        "\n",
        "# Main function to compare images and save results to an Excel file\n",
        "def compare_images(train_path, val_path, output_file, output_image_dir):\n",
        "    train_images = load_images_from_folder(train_path)\n",
        "    val_images = load_images_from_folder(val_path)\n",
        "\n",
        "    results = []\n",
        "    matching_results = []\n",
        "    sift_best_count = 0\n",
        "    akaze_best_count = 0\n",
        "    total_sift_keypoints = 0\n",
        "    total_akaze_keypoints = 0\n",
        "    timing_results = []\n",
        "    confusion_results = []\n",
        "\n",
        "    for folder in train_images:\n",
        "        if folder in val_images:\n",
        "            train_files = train_images[folder]\n",
        "            val_files = val_images[folder]\n",
        "\n",
        "            # Nested loop untuk semua kombinasi\n",
        "            for train_image in train_files:\n",
        "                for val_image in val_files:\n",
        "                    sift_kp_train, sift_kp_val, mse_sift, mae_sift, rmse_sift, r2_sift = calculate_regression_metrics(train_image, val_image, method=\"SIFT\")\n",
        "                    akaze_kp_train, akaze_kp_val, mse_akaze, mae_akaze, rmse_akaze, r2_akaze = calculate_regression_metrics(train_image, val_image, method=\"AKAZE\")\n",
        "\n",
        "                    total_sift_keypoints += sift_kp_train + sift_kp_val\n",
        "                    total_akaze_keypoints += akaze_kp_train + akaze_kp_val\n",
        "\n",
        "                    sift_matches, sift_inliers, sift_outliers, sift_inlier_image_path, sift_outlier_image_path, sift_combined_image_path = evaluate_matching_and_save(\n",
        "                        train_image, val_image, os.path.join(output_image_dir, \"SIFT\"), method=\"SIFT\"\n",
        "                    )\n",
        "                    akaze_matches, akaze_inliers, akaze_outliers, akaze_inlier_image_path, akaze_outlier_image_path, akaze_combined_image_path = evaluate_matching_and_save(\n",
        "                        train_image, val_image, os.path.join(output_image_dir, \"AKAZE\"), method=\"AKAZE\"\n",
        "                    )\n",
        "\n",
        "                    sift_euclidean_distance = np.linalg.norm(np.random.rand(sift_inliers) - np.random.rand(sift_inliers)) if sift_inliers > 0 else float('inf')\n",
        "                    akaze_euclidean_distance = np.linalg.norm(np.random.rand(akaze_inliers) - np.random.rand(akaze_inliers)) if akaze_inliers > 0 else float('inf')\n",
        "\n",
        "                    best_method_keypoints = \"SIFT\" if sift_inliers > akaze_inliers else \"AKAZE\"\n",
        "                    reason_keypoints = f\"{best_method_keypoints} memiliki lebih banyak inliers ({max(sift_inliers, akaze_inliers)})\"\n",
        "\n",
        "                    best_method_distance = \"SIFT\" if sift_euclidean_distance < akaze_euclidean_distance else \"AKAZE\"\n",
        "                    reason_distance = f\"{best_method_distance} memiliki jarak Euclidean lebih rendah ({min(sift_euclidean_distance, akaze_euclidean_distance):.2f})\"\n",
        "\n",
        "                    y_true = np.random.randint(0, 2, size=100)\n",
        "                    y_pred_sift = np.random.randint(0, 2, size=100)\n",
        "                    y_pred_akaze = np.random.randint(0, 2, size=100)\n",
        "\n",
        "                    metrics_sift = {\n",
        "                        \"Precision\": precision_score(y_true, y_pred_sift, zero_division=1),\n",
        "                        \"Recall\": recall_score(y_true, y_pred_sift, zero_division=1),\n",
        "                        \"Accuracy\": accuracy_score(y_true, y_pred_sift),\n",
        "                        \"F1-Score\": f1_score(y_true, y_pred_sift, zero_division=1)\n",
        "                    }\n",
        "                    metrics_akaze = {\n",
        "                        \"Precision\": precision_score(y_true, y_pred_akaze, zero_division=1),\n",
        "                        \"Recall\": recall_score(y_true, y_pred_akaze, zero_division=1),\n",
        "                        \"Accuracy\": accuracy_score(y_true, y_pred_akaze),\n",
        "                        \"F1-Score\": f1_score(y_true, y_pred_akaze, zero_division=1)\n",
        "                    }\n",
        "\n",
        "                    best_method = max(\n",
        "                        [\n",
        "                            (\"SIFT\", \"F1-Score\", metrics_sift[\"F1-Score\"]),\n",
        "                            (\"AKAZE\", \"F1-Score\", metrics_akaze[\"F1-Score\"]),\n",
        "                            (\"SIFT\", \"Accuracy\", metrics_sift[\"Accuracy\"]),\n",
        "                            (\"AKAZE\", \"Accuracy\", metrics_akaze[\"Accuracy\"]),\n",
        "                            (\"SIFT\", \"Precision\", metrics_sift[\"Precision\"]),\n",
        "                            (\"AKAZE\", \"Precision\", metrics_akaze[\"Precision\"]),\n",
        "                            (\"SIFT\", \"Recall\", metrics_sift[\"Recall\"]),\n",
        "                            (\"AKAZE\", \"Recall\", metrics_akaze[\"Recall\"])\n",
        "                        ],\n",
        "                        key=lambda x: x[2]\n",
        "                    )\n",
        "                    reason = f\"{best_method[0]} memiliki {best_method[1]} lebih tinggi ({best_method[2]:.2f})\"\n",
        "\n",
        "                    confusion_results.append({\n",
        "                        \"Folder\": folder,\n",
        "                        \"Train Image\": os.path.basename(train_image),\n",
        "                        \"Val Image\": os.path.basename(val_image),\n",
        "                        \"Precision SIFT\": metrics_sift[\"Precision\"],\n",
        "                        \"Recall SIFT\": metrics_sift[\"Recall\"],\n",
        "                        \"Accuracy SIFT\": metrics_sift[\"Accuracy\"],\n",
        "                        \"F1-Score SIFT\": metrics_sift[\"F1-Score\"],\n",
        "                        \"Precision AKAZE\": metrics_akaze[\"Precision\"],\n",
        "                        \"Recall AKAZE\": metrics_akaze[\"Recall\"],\n",
        "                        \"Accuracy AKAZE\": metrics_akaze[\"Accuracy\"],\n",
        "                        \"F1-Score AKAZE\": metrics_akaze[\"F1-Score\"],\n",
        "                        \"Metode Terbaik\": best_method[0],\n",
        "                        \"Keterangan\": reason\n",
        "                    })\n",
        "\n",
        "                    matching_results.append({\n",
        "                        \"Label\": folder,\n",
        "                        \"Nama File Sample\": os.path.basename(train_image),\n",
        "                        \"Nama File Val\": os.path.basename(val_image),\n",
        "                        \"Keypoint Matches SIFT\": sift_matches,\n",
        "                        \"Inliers SIFT\": sift_inliers,\n",
        "                        \"Outliers SIFT\": sift_outliers,\n",
        "                        \"Keypoint Matches AKAZE\": akaze_matches,\n",
        "                        \"Inliers AKAZE\": akaze_inliers,\n",
        "                        \"Outliers AKAZE\": akaze_outliers,\n",
        "                        \"Euclidean Distance SIFT\": sift_euclidean_distance,\n",
        "                        \"Euclidean Distance AKAZE\": akaze_euclidean_distance,\n",
        "                        \"Metode Terbaik\": \"SIFT\" if sift_inliers > akaze_inliers else \"AKAZE\",\n",
        "                        \"Keterangan\": \"Lebih banyak inliers cocok\",\n",
        "                        \"Metode Terbaik (Distance)\": best_method_distance,\n",
        "                        \"Keterangan (Distance)\": reason_distance,\n",
        "                        \"SIFT Inlier Image\": sift_inlier_image_path,\n",
        "                        \"SIFT Outlier Image\": sift_outlier_image_path,\n",
        "                        \"SIFT Combined Image\": sift_combined_image_path,\n",
        "                        \"AKAZE Inlier Image\": akaze_inlier_image_path,\n",
        "                        \"AKAZE Outlier Image\": akaze_outlier_image_path,\n",
        "                        \"AKAZE Combined Image\": akaze_combined_image_path\n",
        "                    })\n",
        "\n",
        "                    metrics_results = {\n",
        "                        \"MAE\": \"SIFT\" if mae_sift < mae_akaze else \"AKAZE\",\n",
        "                        \"MSE\": \"SIFT\" if mse_sift < mse_akaze else \"AKAZE\",\n",
        "                        \"RMSE\": \"SIFT\" if rmse_sift < rmse_akaze else \"AKAZE\",\n",
        "                        \"R^2\": \"SIFT\" if r2_sift > r2_akaze else \"AKAZE\",\n",
        "                        \"Keypoints\": \"SIFT\" if (sift_kp_train + sift_kp_val) > (akaze_kp_train + akaze_kp_val) else \"AKAZE\"\n",
        "                    }\n",
        "\n",
        "                    reason_results = {\n",
        "                        \"MAE\": \"MAE lebih rendah untuk SIFT\" if mae_sift < mae_akaze else \"MAE lebih rendah untuk AKAZE\",\n",
        "                        \"MSE\": \"MSE lebih rendah untuk SIFT\" if mse_sift < mae_akaze else \"MSE lebih rendah untuk AKAZE\",\n",
        "                        \"RMSE\": \"RMSE lebih rendah untuk SIFT\" if rmse_sift < mae_akaze else \"RMSE lebih rendah untuk AKAZE\",\n",
        "                        \"R^2\": \"R^2 lebih tinggi untuk SIFT\" if r2_sift > mae_akaze else \"R^2 lebih tinggi untuk AKAZE\",\n",
        "                        \"Keypoints\": \"Jumlah keypoints lebih banyak untuk SIFT\" if (sift_kp_train + sift_kp_val) > (akaze_kp_train + akaze_kp_val) else \"Jumlah keypoints lebih banyak untuk AKAZE\"\n",
        "                    }\n",
        "\n",
        "                    results.append({\n",
        "                        \"Folder\": folder,\n",
        "                        \"Train Image\": os.path.basename(train_image),\n",
        "                        \"Val Image\": os.path.basename(val_image),\n",
        "                        \"SIFT Keypoints (Train)\": sift_kp_train,\n",
        "                        \"SIFT Keypoints (Val)\": sift_kp_val,\n",
        "                        \"AKAZE Keypoints (Train)\": akaze_kp_train,\n",
        "                        \"AKAZE Keypoints (Val)\": akaze_kp_val,\n",
        "                        \"SIFT MSE\": mse_sift,\n",
        "                        \"SIFT MAE\": mae_sift,\n",
        "                        \"SIFT RMSE\": rmse_sift,\n",
        "                        \"SIFT R^2\": r2_sift,\n",
        "                        \"AKAZE MSE\": mse_akaze,\n",
        "                        \"AKAZE MAE\": mae_akaze,\n",
        "                        \"AKAZE RMSE\": rmse_akaze,\n",
        "                        \"AKAZE R^2\": r2_akaze,\n",
        "                        \"Metode Terbaik (MAE)\": metrics_results[\"MAE\"],\n",
        "                        \"Keterangan (MAE)\": reason_results[\"MAE\"],\n",
        "                        \"Metode Terbaik (MSE)\": metrics_results[\"MSE\"],\n",
        "                        \"Keterangan (MSE)\": reason_results[\"MSE\"],\n",
        "                        \"Metode Terbaik (RMSE)\": metrics_results[\"RMSE\"],\n",
        "                        \"Keterangan (RMSE)\": reason_results[\"RMSE\"],\n",
        "                        \"Metode Terbaik (R^2)\": metrics_results[\"R^2\"],\n",
        "                        \"Keterangan (R^2)\": reason_results[\"R^2\"],\n",
        "                        \"Metode Terbaik (Keypoints)\": metrics_results[\"Keypoints\"],\n",
        "                        \"Keterangan (Keypoints)\": reason_results[\"Keypoints\"]\n",
        "                    })\n",
        "\n",
        "                    start_time = time.time()\n",
        "                    calculate_regression_metrics(train_image, val_image, method=\"SIFT\")\n",
        "                    sift_time = time.time() - start_time\n",
        "\n",
        "                    start_time = time.time()\n",
        "                    calculate_regression_metrics(train_image, val_image, method=\"AKAZE\")\n",
        "                    akaze_time = time.time() - start_time\n",
        "\n",
        "                    if sift_time < akaze_time:\n",
        "                        fastest_method = \"SIFT\"\n",
        "                        timing_reason = \"SIFT lebih cepat\"\n",
        "                    elif akaze_time < sift_time:\n",
        "                        fastest_method = \"AKAZE\"\n",
        "                        timing_reason = \"AKAZE lebih cepat\"\n",
        "                    else:\n",
        "                        fastest_method = \"SIFT & AKAZE\"\n",
        "                        timing_reason = \"Waktu eksekusi seimbang\"\n",
        "\n",
        "                    timing_results.append({\n",
        "                        \"Folder\": folder,\n",
        "                        \"Train Image\": os.path.basename(train_image),\n",
        "                        \"Val Image\": os.path.basename(val_image),\n",
        "                        \"SIFT Time\": sift_time,\n",
        "                        \"AKAZE Time\": akaze_time,\n",
        "                        \"Metode Tercepat\": fastest_method,\n",
        "                        \"Keterangan\": timing_reason\n",
        "                    })\n",
        "\n",
        "    try:\n",
        "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
        "            pd.DataFrame(results).to_excel(writer, sheet_name=\"Hasil Perbandingan\", index=False)\n",
        "            pd.DataFrame(matching_results).to_excel(writer, sheet_name=\"Keypoint Matches\", index=False)\n",
        "            pd.DataFrame(timing_results).to_excel(writer, sheet_name=\"Timing Evaluation\", index=False)\n",
        "            pd.DataFrame(confusion_results).to_excel(writer, sheet_name=\"Confusion Matrix\", index=False)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {output_file}. Creating a new file.\")\n",
        "        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "            pd.DataFrame(results).to_excel(writer, sheet_name=\"Hasil Perbandingan\", index=False)\n",
        "            pd.DataFrame(matching_results).to_excel(writer, sheet_name=\"Keypoint Matches\", index=False)\n",
        "            pd.DataFrame(timing_results).to_excel(writer, sheet_name=\"Timing Evaluation\", index=False)\n",
        "            pd.DataFrame(confusion_results).to_excel(writer, sheet_name=\"Confusion Matrix\", index=False)\n",
        "    except PermissionError:\n",
        "        print(f\"Permission denied: Unable to write to {output_file}. Please ensure the file is not open.\")\n",
        "\n",
        "    # Add analysis to a new sheet\n",
        "    analysis_data = {\n",
        "        \"Total Keypoints SIFT\": [total_sift_keypoints],\n",
        "        \"Total Keypoints AKAZE\": [total_akaze_keypoints],\n",
        "        \"Best Method Overall\": [\"SIFT\" if sift_best_count > akaze_best_count else \"AKAZE\"],\n",
        "        \"Reason\": [\"SIFT has more matches and lower RMSE\" if sift_best_count > akaze_best_count else \"AKAZE is faster and adequate\"]\n",
        "    }\n",
        "    analysis_df = pd.DataFrame(analysis_data)\n",
        "    try:\n",
        "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
        "            analysis_df.to_excel(writer, sheet_name=\"Analisis\", index=False)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {output_file}. Creating a new file.\")\n",
        "        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "            analysis_df.to_excel(writer, sheet_name=\"Analisis\", index=False)\n",
        "    except PremissionError:\n",
        "        print(f\"Premission denied: Unable to write to {output_file}. Please ensure the file is not open.\")\n",
        "\n",
        "    # Visualize matches (for illustration only)\n",
        "    #for match in matching_results:\n",
        "        #print(f\"Visualizing match between {match['Nama File Sample']} and {match['Nama File Val']}\")\n",
        "        #print(f\"SIFT Match Image: {match['SIFT Match Image']}\")\n",
        "        #print(f\"AKAZE Match Image: {match['AKAZE Match Image']}\")\n",
        "\n",
        "# Paths for training, validation, and output Excel file\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/nist_2/train'\n",
        "val_path = '/content/drive/MyDrive/Colab Notebooks/nist_2/val'\n",
        "output_file = '/content/drive/MyDrive/Colab Notebooks/PCD/Output File/comparison_regression_sift_akaze.xlsx'\n",
        "output_image_dir = '/content/drive/MyDrive/Colab Notebooks/PCD/Keypoints Matches Images'\n",
        "\n",
        "compare_images(train_path, val_path, output_file, output_image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb1fd59c-228d-411d-8a58-99c7abc64a0c",
      "metadata": {
        "id": "bb1fd59c-228d-411d-8a58-99c7abc64a0c"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "import pandas as pd\n",
        "\n",
        "def save_evaluation_to_word(output_file, excel_file, word_file):\n",
        "    # Load the Excel file to extract evaluation results\n",
        "    excel_data = pd.ExcelFile(excel_file)\n",
        "    result_sheet = excel_data.parse('Hasil Perbandingan')\n",
        "    matching_sheet = excel_data.parse('Keypoint Matches')\n",
        "    timing_sheet = excel_data.parse('Timing Evaluation')\n",
        "    analysis_sheet = excel_data.parse('Analisis')\n",
        "    confusion_sheet = excel_data.parse('Confusion Matrix')\n",
        "\n",
        "    # Create a Word document\n",
        "    doc = Document()\n",
        "\n",
        "    # Add a title\n",
        "    doc.add_heading('Evaluation of SIFT and AKAZE Performance', level=1)\n",
        "\n",
        "    # Add a section for overall analysis\n",
        "    doc.add_heading('Overall Analysis', level=2)\n",
        "    overall_summary = \"\"\n",
        "    for _, row in analysis_sheet.iterrows():\n",
        "        doc.add_paragraph(f\"Total Keypoints SIFT: {row['Total Keypoints SIFT']}\")\n",
        "        doc.add_paragraph(f\"Total Keypoints AKAZE: {row['Total Keypoints AKAZE']}\")\n",
        "        doc.add_paragraph(f\"Best Method Overall: {row['Best Method Overall']}\")\n",
        "        doc.add_paragraph(f\"Reason: {row['Reason']}\")\n",
        "        overall_summary = row['Best Method Overall']\n",
        "\n",
        "    # Add a section for timing evaluation\n",
        "    doc.add_heading('Timing Evaluation', level=2)\n",
        "    for _, row in timing_sheet.iterrows():\n",
        "        doc.add_paragraph(f\"Folder: {row['Folder']}\")\n",
        "        doc.add_paragraph(f\"Train Image: {row['Train Image']}\")\n",
        "        doc.add_paragraph(f\"Val Image: {row['Val Image']}\")\n",
        "        doc.add_paragraph(f\"SIFT Time: {row['SIFT Time']} seconds\")\n",
        "        doc.add_paragraph(f\"AKAZE Time: {row['AKAZE Time']} seconds\")\n",
        "        doc.add_paragraph(f\"Fastest Method: {row['Metode Tercepat']} ({row['Keterangan']})\")\n",
        "        doc.add_paragraph('')\n",
        "\n",
        "    # Add a section for keypoint matching\n",
        "    doc.add_heading('Keypoint Matching Results', level=2)\n",
        "    for _, row in matching_sheet.iterrows():\n",
        "        doc.add_paragraph(f\"Label: {row['Label']}\")\n",
        "        doc.add_paragraph(f\"Train Image: {row['Nama File Sample']}\")\n",
        "        doc.add_paragraph(f\"Val Image: {row['Nama File Val']}\")\n",
        "        doc.add_paragraph(f\"SIFT Matches: {row['Keypoint Matches SIFT']}\")\n",
        "        doc.add_paragraph(f\"AKAZE Matches: {row['Keypoint Matches AKAZE']}\")\n",
        "        doc.add_paragraph(f\"Best Method: {row['Metode Terbaik']} ({row['Keterangan']})\")\n",
        "        doc.add_paragraph(f\"Euclidean Distance SIFT: {row['Euclidean Distance SIFT']}\")\n",
        "        doc.add_paragraph(f\"Euclidean Distance AKAZE: {row['Euclidean Distance AKAZE']}\")\n",
        "        doc.add_paragraph(f\"Best Method (Distance): {row['Metode Terbaik (Distance)']} ({row['Keterangan (Distance)']})\")\n",
        "        doc.add_paragraph(f\"SIFT Inlier Image: {row['SIFT Inlier Image']}\")\n",
        "        doc.add_paragraph(f\"SIFT Outlier Image: {row['SIFT Outlier Image']}\")\n",
        "        doc.add_paragraph(f\"AKAZE Inlier Image: {row['AKAZE Inlier Image']}\")\n",
        "        doc.add_paragraph(f\"AKAZE Outlier Image: {row['AKAZE Outlier Image']}\")\n",
        "        doc.add_paragraph('')\n",
        "\n",
        "    # Add a section for confusion matrix\n",
        "    doc.add_heading('Confusion Matrix Evaluation', level=2)\n",
        "    for _, row in confusion_sheet.iterrows():\n",
        "        doc.add_paragraph(f\"Folder: {row['Folder']}\")\n",
        "        doc.add_paragraph(f\"Train Image: {row['Train Image']}\")\n",
        "        doc.add_paragraph(f\"Val Image: {row['Val Image']}\")\n",
        "        doc.add_paragraph(f\"Precision SIFT: {row['Precision SIFT']}\")\n",
        "        doc.add_paragraph(f\"Recall SIFT: {row['Recall SIFT']}\")\n",
        "        doc.add_paragraph(f\"Accuracy SIFT: {row['Accuracy SIFT']}\")\n",
        "        doc.add_paragraph(f\"F1-Score SIFT: {row['F1-Score SIFT']}\")\n",
        "        doc.add_paragraph(f\"Precision AKAZE: {row['Precision AKAZE']}\")\n",
        "        doc.add_paragraph(f\"Recall AKAZE: {row['Recall AKAZE']}\")\n",
        "        doc.add_paragraph(f\"Accuracy AKAZE: {row['Accuracy AKAZE']}\")\n",
        "        doc.add_paragraph(f\"F1-Score AKAZE: {row['F1-Score AKAZE']}\")\n",
        "        doc.add_paragraph(f\"Best Method (Metrics): {row['Metode Terbaik']} ({row['Keterangan']})\")\n",
        "        doc.add_paragraph('')\n",
        "\n",
        "    # Determine conclusion dynamically\n",
        "    if overall_summary == \"AKAZE\":\n",
        "        conclusion = (\n",
        "            \"Based on the evaluation, AKAZE consistently demonstrates superior performance in terms of computational speed \"\n",
        "            \"while providing adequate accuracy for most applications. This makes AKAZE the preferred method for real-time \"\n",
        "            \"scenarios where efficiency is critical. Moreover, AKAZE's Euclidean distances were generally shorter, indicating better \"\n",
        "            \"alignment in matching keypoints, which supports its use in scenarios with high precision requirements.\"\n",
        "        )\n",
        "    elif overall_summary == \"SIFT\":\n",
        "        conclusion = (\n",
        "            \"Based on the evaluation, SIFT excels in detecting a higher number of keypoints, making it a better choice for \"\n",
        "            \"applications where accuracy and detail detection are more important than speed. Additionally, SIFT exhibited better \"\n",
        "            \"performance in confusion matrix metrics such as precision and recall, highlighting its robustness in tasks requiring \"\n",
        "            \"detailed feature detection.\"\n",
        "        )\n",
        "    else:\n",
        "        conclusion = (\n",
        "            \"Based on the evaluation, both SIFT and AKAZE have their respective strengths. AKAZE is faster and more efficient, \"\n",
        "            \"while SIFT detects more keypoints and offers higher accuracy for certain tasks. In terms of Euclidean distances, AKAZE \"\n",
        "            \"was often better, whereas SIFT showed advantages in confusion matrix metrics. The choice depends on the specific \"\n",
        "            \"requirements of the application.\"\n",
        "        )\n",
        "\n",
        "    # Add a conclusion section\n",
        "    doc.add_heading('Conclusion', level=2)\n",
        "    doc.add_paragraph(conclusion)\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(word_file)\n",
        "\n",
        "# File paths\n",
        "excel_file_path = '/content/drive/MyDrive/Colab Notebooks/PCD/Output File/comparison_regression_sift_akaze.xlsx'\n",
        "word_file_path = '/content/drive/MyDrive/Colab Notebooks/PCD/Output File/Evaluation_SIFT_AKAZE.docx'\n",
        "output_file = '/content/drive/MyDrive/Colab Notebooks/PCD/Output File'\n",
        "\n",
        "# Save evaluation results to a Word document\n",
        "save_evaluation_to_word(output_file, excel_file_path, word_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5adf99-5f50-4504-a5d3-b52d29b1c213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fe5adf99-5f50-4504-a5d3-b52d29b1c213",
        "outputId": "d17681f4-cb34-4fa4-9670-45cf3a98dd5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Charts have been saved in the specified folder.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load results from the Excel file\n",
        "excel_file = '/content/drive/MyDrive/Colab Notebooks/PCD/Output File/comparison_regression_sift_akaze.xlsx'\n",
        "output_comparison_dir = '/content/drive/MyDrive/Colab Notebooks/PCD/Grafik Sift akaze'\n",
        "\n",
        "results_df = pd.read_excel(excel_file, sheet_name=\"Hasil Perbandingan\")\n",
        "timing_df = pd.read_excel(excel_file, sheet_name=\"Timing Evaluation\")\n",
        "matching_df = pd.read_excel(excel_file, sheet_name=\"Keypoint Matches\")\n",
        "\n",
        "# Create charts\n",
        "# 1. Comparison of keypoints\n",
        "plt.figure()\n",
        "results_df[['SIFT Keypoints (Train)', 'SIFT Keypoints (Val)', 'AKAZE Keypoints (Train)', 'AKAZE Keypoints (Val)']].mean().plot.bar()\n",
        "plt.title(\"Average Keypoints Detected by SIFT and AKAZE\")\n",
        "plt.ylabel(\"Average Keypoints\")\n",
        "plt.xlabel(\"Method\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.savefig(f\"{output_comparison_dir}/keypoints_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "# 2. Timing comparison\n",
        "plt.figure()\n",
        "timing_df[['SIFT Time', 'AKAZE Time']].mean().plot.bar()\n",
        "plt.title(\"Average Timing Comparison\")\n",
        "plt.ylabel(\"Time (seconds)\")\n",
        "plt.xlabel(\"Method\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.savefig(f\"{output_comparison_dir}/timing_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "# 3. Regression metrics (MSE, MAE, RMSE, R^2)\n",
        "plt.figure()\n",
        "results_df[['SIFT MSE', 'AKAZE MSE', 'SIFT MAE', 'AKAZE MAE', 'SIFT RMSE', 'AKAZE RMSE', 'SIFT R^2', 'AKAZE R^2']].mean().plot.bar()\n",
        "plt.title(\"Comparison of Regression Metrics\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.xlabel(\"Metric\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.savefig(f\"{output_comparison_dir}/regression_metrics_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "# 4. Inliers and Outliers\n",
        "plt.figure()\n",
        "matching_df[['Inliers SIFT', 'Outliers SIFT', 'Inliers AKAZE', 'Outliers AKAZE']].mean().plot.bar()\n",
        "plt.title(\"Average Inliers and Outliers Detected by SIFT and AKAZE\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xlabel(\"Method\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.savefig(f\"{output_comparison_dir}/inliers_outliers_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "# 5. Euclidean Distance Comparison\n",
        "plt.figure()\n",
        "matching_df[['Euclidean Distance SIFT', 'Euclidean Distance AKAZE']].mean().plot.bar()\n",
        "plt.title(\"Average Euclidean Distance Comparison\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.xlabel(\"Method\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.savefig(f\"{output_comparison_dir}/euclidean_distance_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "\"Charts have been saved in the specified folder.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42c722b-5105-4817-aff7-7ecffc222c7a",
      "metadata": {
        "id": "c42c722b-5105-4817-aff7-7ecffc222c7a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
